{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of (v4) Copy of (v3) Copy of generating_music.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IWzaYdTDQat"
      },
      "source": [
        "# Overview of Notebook Functions\n",
        " 1. read data with music21\n",
        " 2. map input\n",
        " 3. sequence input\n",
        " 4. package network input into 1 pickle \n",
        " 5. train model\n",
        " 6. save best weights into hdf5 \n",
        "\n",
        "# Notebook Use After Training \n",
        " 8. use weigths in hdf5 to generate new notes \n",
        " 9. unmap sequences\n",
        " 10. add to music21 stream  \n",
        " 11. output midi file\n",
        "\n",
        "**Note:** After first reading in data from the midi files, the notebook will produce pickled files of sequences and normalizers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co2pZDD4Ql1v"
      },
      "source": [
        "from music21 import converter, interval, instrument, note, chord, common, stream, midi, tempo, pitch\n",
        "import glob\n",
        "import concurrent.futures\n",
        "import pickle \n",
        "import numpy as np \n",
        "from keras.utils import np_utils "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU73QhtdhHVV"
      },
      "source": [
        "def isolate(mfile):\n",
        "    orig_midi = converter.parse(mfile) \n",
        "    key = orig_midi.analyze(\"key\")\n",
        "\n",
        "    if key.tonic == \"C\": \n",
        "        return None  \n",
        "\n",
        "    iv = interval.Interval(key.tonic, pitch.Pitch(\"C\")) \n",
        "    midi = orig_midi.transpose(iv) \n",
        "    midi = midi.flat \n",
        "    \n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    if parts: \n",
        "        for instr in parts: \n",
        "            if instr.partName and \"Piano\" in instr.partName: # xml uses variations like \"Grand Piano\" \n",
        "                return [mfile, instr] \n",
        "\n",
        "    return None\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRVlmFuj214C"
      },
      "source": [
        "def parse_notes(score):\n",
        "    score_elems = score.recurse()\n",
        "\n",
        "    note_list = [] \n",
        "    pitches = [] # [[treble, bass], ...] \n",
        "    elem_lengths = [] # [[treble, bass], ...] \n",
        "    offsets = [] \n",
        "    prev_offset = -1 \n",
        "    for element in score_elems: # score: # score_elems: \n",
        "\n",
        "        if element.duration.quarterLength <= 0: \n",
        "            continue \n",
        "\n",
        "        if isinstance(element, note.Note): \n",
        "            if element.offset != prev_offset: # this is a note in a brand new time offset \n",
        "                note_list.append(str(element.pitch)) \n",
        "                pitches.append([element.pitch]) \n",
        "                elem_lengths.append([round(float(element.duration.quarterLength), 8)]) \n",
        "                offsets.append([float(element.offset)]) \n",
        "            else: # this is still in the old time offset \n",
        "                if len(pitches[-1]) != 2: # and the old time offset can hold more notes \n",
        "                    pitches[-1].append(element.pitch) \n",
        "                    elem_lengths[-1].append(round(float(element.duration.quarterLength), 8)) \n",
        "                    offsets[-1].append(float(element.offset)) \n",
        "            prev_offset = element.offset \n",
        "\n",
        "        elif isinstance(element, chord.Chord): \n",
        "            if element.offset != prev_offset: \n",
        "                temp = '.'.join(str(n.pitch) for n in element)\n",
        "                note_list.append(temp.split('.')) \n",
        "                pitches.append([[k.pitch for k in element]]) # a chord \n",
        "                elem_lengths.append([round(float(element.duration.quarterLength), 8)]) \n",
        "                offsets.append([float(element.offset)]) \n",
        "            else: \n",
        "                if len(pitches[-1]) != 2: \n",
        "                    pitches[-1].append([k.pitch for k in element]) \n",
        "                    elem_lengths[-1].append(round(float(element.duration.quarterLength), 8)) \n",
        "                    offsets[-1].append(float(element.offset)) \n",
        "            prev_offset = element.offset \n",
        "\n",
        "        elif isinstance(element, note.Rest):\n",
        "            if element.offset != prev_offset: \n",
        "                note_list.append(None) \n",
        "                pitches.append([None]) \n",
        "                elem_lengths.append([round(float(element.duration.quarterLength), 8)]) \n",
        "                offsets.append([float(element.offset)]) \n",
        "            else: \n",
        "                if len(pitches[-1]) != 2: \n",
        "                    pitches[-1].append(None) \n",
        "                    elem_lengths[-1].append(round(float(element.duration.quarterLength), 8)) \n",
        "                    offsets[-1].append(float(element.offset)) \n",
        "            prev_offset = element.offset \n",
        "\n",
        "\n",
        "    def fixitup(arr, addNone=True): \n",
        "        for idx in range(len(arr)): \n",
        "            frame = arr[idx]\n",
        "\n",
        "            if len(frame) < 2: \n",
        "                if addNone: \n",
        "                    frame.append(None) \n",
        "                else: \n",
        "                    length_top = frame[0] \n",
        "                    if idx > 1: \n",
        "                        arr[idx-1][1] += length_top # extend length of previous \n",
        "                        frame.append(0) # frame[0] \n",
        "                    else: \n",
        "                        frame.append(frame[0]) \n",
        "     \n",
        "    fixitup(pitches, addNone=True) \n",
        "    fixitup(elem_lengths, addNone=False) \n",
        "    fixitup(offsets) \n",
        "     \n",
        "    return (note_list, elem_lengths, pitches, offsets) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgdG1NK4ZN8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e10ba4-f780-44c8-cdb6-dc0da5ae6811"
      },
      "source": [
        "c = pitch.Pitch(63) \n",
        "print(c, pitch.Pitch(63).ps == pitch.Pitch(\"Eb4\").ps == pitch.Pitch('D#4').ps) \n",
        " \n",
        "def numerical(name): \n",
        "    try: \n",
        "        return pitch.Pitch(name).ps \n",
        "    except Exception: \n",
        "        print(\"Bad name\", name)\n",
        " "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E-4 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ0-lKJt27ID"
      },
      "source": [
        "def pstr(mpitch): \n",
        "\n",
        "    def octv(k): \n",
        "        v = k.octave \n",
        "        # v = 4 \n",
        "        r = pitch.Pitch(k.name+str(v)) \n",
        "        return r\n",
        "         \n",
        "    if not mpitch or (isinstance(mpitch, str) and \"r\" in mpitch):\n",
        "        return \"r\"  \n",
        "    if isinstance(mpitch, str) and \"b\" in mpitch: \n",
        "        print(\"b is not allowed!\") \n",
        "        raise \n",
        "        return \"r\" \n",
        "    if isinstance(mpitch, list) or isinstance(mpitch, set): \n",
        "        mpitch = [octv(k) for k in mpitch] \n",
        "        return \"-\".join([str(k.ps) for k in mpitch]) \n",
        "    else: \n",
        "        mpitch = octv(mpitch) \n",
        "        return str(mpitch.ps) \n",
        "\n",
        "def map_values(notes, lengths, pitches, offsets, counter): \n",
        "    enum_count, all_names, name_to_num = counter.enum_count, counter.all_names, counter.name_to_num \n",
        "    all_names = [pstr(k[0]) for k in pitches] + [pstr(k[1]) for k in pitches]\n",
        "\n",
        "    for k in all_names:\n",
        "      if k not in name_to_num:\n",
        "          name_to_num[k] = enum_count\n",
        "          enum_count += 1\n",
        "    vector_list = []\n",
        "\n",
        "    for index in range(min(len(pitches), len(lengths))): \n",
        "        music_vector = []\n",
        "        length = max(lengths[index][0], lengths[index][1]) \n",
        "        if length <= 8: \n",
        "            treble, bass = pstr(pitches[index][0]), pstr(pitches[index][1]) \n",
        "            treble_length, bass_length = lengths[index][0], lengths[index][1] \n",
        "            music_vector = [name_to_num[treble], treble_length, name_to_num[bass], bass_length] \n",
        "            vector_list.append(music_vector)\n",
        "\n",
        "    counter.enum_count = enum_count \n",
        "    counter.all_names = all_names \n",
        "    counter.name_to_num = name_to_num \n",
        "    return (vector_list, counter) \n",
        "     "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7pDEUP-TwC0"
      },
      "source": [
        "%rm -rvf stream* "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCy8Xqj16uqT"
      },
      "source": [
        "import sys \n",
        "import copy \n",
        "import math \n",
        "from numpy import argmax \n",
        "from keras.utils import normalize, to_categorical \n",
        "def qround(value): \n",
        "    return math.ceil(value*4)/4 \n",
        "def sequence_values(counter, normalizers): # mapped_notes, enum_count, name_to_num, \n",
        "    mapped_notes, enum_count, name_to_num = counter.mapped_notes, counter.enum_count, counter.name_to_num \n",
        "    max_duration = counter.max_duration\n",
        "    max_offset = counter.max_offset\n",
        "    seq_size = normalizers.seq_size \n",
        "    nw_in, nw_out = [], [] \n",
        "    all_pkgs = set()\n",
        "\n",
        "    for vector_list in mapped_notes: \n",
        "        for idx in range(0, len(vector_list)): \n",
        "            music_vector = copy.deepcopy(vector_list[idx]) \n",
        "            result = (music_vector[0], qround(music_vector[1]), \n",
        "                      music_vector[2], qround(music_vector[3])) \n",
        "            all_pkgs.add(result) \n",
        "            vector_list[idx] = result \n",
        "         \n",
        "    pkg_to_int = dict([(pkg, number) for number, pkg in enumerate(list(all_pkgs))]) \n",
        "    mean, std = np.mean(list(pkg_to_int.values())), np.std(list(pkg_to_int.values())) \n",
        "    print(\"packaged notes, there are\", len(pkg_to_int), \"packages. \\n\\tpkgs=\", list(all_pkgs)[0:5], \"...\") \n",
        "    for vector_list in mapped_notes: \n",
        "        for k in range(0, len(vector_list) - seq_size - 1): \n",
        "            window = vector_list[k:k+seq_size] # [[pitch, duration], ...] \n",
        "            expected = vector_list[k+seq_size] # [pitch, duration] \n",
        "            nw_in.append([pkg_to_int[k] for k in window]) \n",
        "            nw_out.append(pkg_to_int[expected]) \n",
        "\n",
        "    print(\"Our code is done,\", len(nw_in), len(nw_out)) \n",
        "    num_pkgs, num_windows, seq_size = len(pkg_to_int), len(nw_in), len(nw_in[0]) \n",
        "    normalizers.mpc, normalizers.spc, normalizers.mln, normalizers.sln = 0, 0, 0, 0 \n",
        "    normalizers.pkg_to_int = pkg_to_int \n",
        "    normalizers.mean, normalizers.std = mean, std \n",
        "    normalizers.num_pkgs = num_pkgs \n",
        "\n",
        "    print(num_windows, \"windows, each with\", seq_size, \"frames, (each with\", 4, \"features that map to 1 number), \", \n",
        "        \"total=window*frame*1=\", num_windows*seq_size*1) \n",
        "    nw_in = np.array(nw_in).astype(np.float32) \n",
        "    nw_out = np.array(nw_out).astype(np.float32) \n",
        "     \n",
        "    nw_in = np.reshape(nw_in, (num_windows, seq_size, 1)) \n",
        "    nw_out = to_categorical(nw_out) \n",
        "\n",
        "    print(\"Input and output shapes:\", nw_in.shape, nw_out.shape) \n",
        "    return (nw_in, nw_out, counter, normalizers) \n",
        "     "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhAx4TSIvZzR"
      },
      "source": [
        "!pip install keras-self-attention \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Activation, Dense, Bidirectional, LSTM, Dropout, Flatten, TimeDistributed, Reshape \n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.optimizers import SGD \n",
        "from keras.optimizers import Adam \n",
        "from keras_self_attention import SeqSelfAttention\n",
        "\n",
        "def basic_network(counter, normalizers): # * \n",
        "    model = Sequential() \n",
        "    model.add(LSTM(512, input_shape=(normalizers.seq_size, 1), return_sequences=True)) \n",
        "    model.add(LSTM(512, input_shape=(normalizers.seq_size, 1), return_sequences=False)) \n",
        "    model.add(Flatten()) \n",
        "    model.add(Dense(normalizers.num_pkgs)) \n",
        "    model.add(Activation('softmax')) \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # loss mae, mse, categorical_crossentropy, opt rmsprop \n",
        "    return model\n",
        "\n",
        "def load_model(filename, counter, normalizers): \n",
        "    model = basic_network(counter, normalizers) \n",
        "    model.load_weights(filename) \n",
        "    return model\n",
        "\n",
        "def train(model, nw_in, nw_out, num_epochs=100): \n",
        "    fp = \"weights.best.hdf5\" \n",
        "    checkpoint = ModelCheckpoint(fp, monitor='loss', verbose=1, save_best_only=True) \n",
        "    model.fit(nw_in, nw_out, epochs=num_epochs, batch_size=256, callbacks=[checkpoint]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRZo_XycDaXd"
      },
      "source": [
        "def unmap_values(complete, counter, normalizers):\n",
        "    # input: list of music vectors, counter object\n",
        "    # output: music21 stream object\n",
        "    # music_stream = stream.Stream()\n",
        "\n",
        "    print(\"spc: \", normalizers.spc)\n",
        "    print(\"mpc: \", normalizers.mpc)\n",
        "    print(\"sln: \", normalizers.sln)\n",
        "    print(\"mln: \", normalizers.mln)\n",
        "    top, bottom = stream.Part(), stream.Part() \n",
        "    int_to_pkg = {num:name for name, num in normalizers.pkg_to_int.items()} \n",
        "    print(\"int_to_pkg len \", len(int_to_pkg), \": \", int_to_pkg) \n",
        "    num_to_name = {num:name for name, num in counter.name_to_num.items()}\n",
        "    off, count = 0, 0 \n",
        "    top.insert(0, instrument.Piano()) \n",
        "    bottom.insert(0, instrument.Piano()) \n",
        "    def add_to_stream(category, is_treble, i=0, j=1, off=0): \n",
        "        if not is_treble: \n",
        "            i, j = 2, 3 \n",
        "        music_vector = int_to_pkg[category] \n",
        "        pitch, length = music_vector[i], music_vector[j] \n",
        "\n",
        "        pitch = round(pitch)\n",
        "        if length < 0 or pitch < 0:\n",
        "            print(\"ERR \", is_treble, \")\", [length, pitch])\n",
        "            return\n",
        "\n",
        "        if length > 8: \n",
        "            length = 0.5\n",
        "\n",
        "        if pitch not in num_to_name.keys(): \n",
        "            print(\"ERR\", is_treble, \")\", category, \"=>\", music_vector, \"=>\", [pitch, length], \"=>\", \"?\") \n",
        "            return \n",
        "        elem_name = num_to_name[pitch] # num_to_name[pitch], \"-\".join(list(num_to_name[pitch]))\n",
        "\n",
        "        if elem_name == 'b': \n",
        "            return # refuse to add anything to stream\n",
        "             \n",
        "        if elem_name == 'r':\n",
        "            elem = note.Rest() \n",
        "        elif '-' not in elem_name:\n",
        "            elem = note.Note(int(float(elem_name)))\n",
        "        else:\n",
        "            pitch_arr = elem_name.split('-')\n",
        "            pitch_arr = [int(float(x)) for x in pitch_arr]\n",
        "            elem = chord.Chord(pitch_arr)\n",
        "            \n",
        "        elem.storedInstrument = instrument.Piano()\n",
        "        elem.duration.quarterLength = length\n",
        "\n",
        "        if is_treble: \n",
        "            top.append(elem)  \n",
        "        else: \n",
        "            bottom.insert(off, elem) \n",
        "        print(is_treble, \")\", category, \"=>\", music_vector, \"=>\", [pitch, length], \"=>\", \n",
        "              elem, \", length:\", elem.duration.quarterLength, \", off:\", off, \", offset:\", elem.offset) \n",
        "        return elem \n",
        "     \n",
        "    for category in complete: \n",
        "        tre = add_to_stream(category, True, 0, 1, off) \n",
        "        bae = add_to_stream(category, False, 2, 3, tre.offset) \n",
        "        off += 0.5 \n",
        "        count += 1 \n",
        "\n",
        "    music_stream = stream.Stream([top, bottom]) \n",
        "    return music_stream\n",
        "\n",
        "from datetime import datetime \n",
        "def stream_file(stream, title=\"\"): \n",
        "    %mkdir -p stream_out \n",
        "    %cd stream_out \n",
        "    stream.write('midi', fp=\"stream_\"+str(datetime.now())+\"_demo\"+title+\".mid\") \n",
        "    %cd .. \n",
        "     "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWux_8d-O-Sq"
      },
      "source": [
        "import copy \n",
        "def use_model(model, nw_in, counter): \n",
        "    # nw_in is [window, window, ...] \n",
        "    start = int(len(nw_in)/2)\n",
        "    pattern_in = list(nw_in[start]) # python list of ndarrays dtype=float32. do not convert ndarray to python list. len of pattern_in is sequence size. \n",
        "    seq_size = len(pattern_in) \n",
        "    complete = list(nw_in[start])\n",
        "\n",
        "    print(\"starting sequence window\", complete[0:10], \"...\")\n",
        "\n",
        "    for idx in range(100): \n",
        "        print(\"generating note\", idx, \";\", end=\" \") \n",
        "        ptn = np.asarray(pattern_in) \n",
        "        prediction_input = np.reshape(ptn, (1, seq_size, -1))\n",
        "        \n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "        num_cat = len(prediction[0]) \n",
        "        predicted_next = np.argmax(prediction)\n",
        "\n",
        "        if idx % 4 == 0: \n",
        "            predicted_next = np.random.choice(num_cat, 1, p=prediction[0])[0]\n",
        "             \n",
        "        complete.append(np.asarray(predicted_next, dtype='float32').reshape(1)) # numpy array reshape into list. so 419 => nparray(419.0) => nparray([419.0]) \n",
        "        pattern_in = complete[idx:idx+seq_size]\n",
        "    return [int(k) for k in complete] "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF18-wTffQS8"
      },
      "source": [
        "def begin_train(nw_in, nw_out, counter, normalizers): \n",
        "    model = basic_network(counter, normalizers) \n",
        "    model.summary() \n",
        "    train(model, nw_in, nw_out, num_epochs=500) "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs5762tD3Mpi"
      },
      "source": [
        "import os.path \n",
        "import math \n",
        "import sys \n",
        "from datetime import datetime \n",
        " \n",
        "count = 0 \n",
        "\n",
        "# if stop_count negative, will read all files\n",
        "debug, stop_count = False, -1\n",
        "\n",
        "# file names\n",
        "nw_pickle, search = \"nw.pkl\", \"./pianoonly-midi/\"\n",
        "normalize_pickle = \"normalize.pkl\"\n",
        "!rm -v music21parse.mid unmap_demo.mid \n",
        "\n",
        "class Counters:\n",
        "    def __init__(self):\n",
        "        self.enum_count = 0 \n",
        "        self.unique_frames = 0 \n",
        "        self.all_names = [] \n",
        "        self.name_to_num = {} \n",
        "        self.mapped_notes = [] \n",
        "        self.max_duration = 0\n",
        "        self.max_offset = 0\n",
        "\n",
        "class Normalization:\n",
        "    def __init__(self): \n",
        "        self.pkg_to_int = dict() \n",
        "        self.num_pkgs = 0 \n",
        "        self.mean = 0 \n",
        "        self.std = 0 \n",
        "        self.seq_size = 64 \n",
        "        self.mpc = 0 \n",
        "        self.spc = 0 \n",
        "        self.mln = 0 \n",
        "        self.sln = 0 \n",
        "     \n",
        "c = Counters()\n",
        "n = Normalization()\n",
        "# checks if a pickled sequence file is present\n",
        "if os.path.isfile(nw_pickle): \n",
        "    print(\"this is just to let you know that the network pickle file is being used, press any key to confirm\") \n",
        "    consume = input() \n",
        "    print(\"reading from network pickle...\") \n",
        "    nwfile = open(nw_pickle, \"rb\") \n",
        "    print(\"(1/2) loading...\") \n",
        "    nw = pickle.load(nwfile) \n",
        "    print(\"(2/2) parsing...\") \n",
        "    nw_in, nw_out, c.enum_count, c.max_duration, c.name_to_num = nw[0], nw[1], nw[2], nw[3], nw[4] \n",
        "    nwfile.close() \n",
        "    print(\"nw_out has\", len(nw_out), \"notes, about\", math.ceil(len(nw_out)/450), \"songs\") \n",
        "    print(\"enum_count\", nw[2], \"max_duration\", nw[3]) \n",
        "    print(\"name_to_num has keys\", list(nw[4].keys())[:5], \"...\") \n",
        "    print(\"done, starting to train...\")\n",
        "\n",
        "    print(\"reading from normalizers pickle...\")\n",
        "    nrmlfile = open(normalize_pickle, \"rb\")\n",
        "    print(\"(1/2) loading...\") \n",
        "    n = pickle.load(nrmlfile)\n",
        "    print(\"(2/2) parsing...\") \n",
        "    print(\"there are\", len(n.pkg_to_int), \"categories\") \n",
        "\n",
        "    # checks if trained model is present \n",
        "    if os.path.isfile(\"weights.best.hdf5\"): \n",
        "        print(\"generating notes...\")\n",
        "        model = load_model(\"weights.best.hdf5\", c, n) \n",
        "        result = use_model(model, nw_in, c) \n",
        "        print(\"RESULT\", result) \n",
        "        result_stream = unmap_values(result, c, n) \n",
        "        print(\"Output result midi file\")\n",
        "        result_stream.write('midi', fp=\"generated_\"+str(datetime.now())+\"_demo.mid\")\n",
        "        print(\"midi file generated...\")\n",
        "        raise \n",
        "    else: \n",
        "        print(\"No weights, training model...\")\n",
        "        begin_train(nw_in, nw_out, c, n) \n",
        "        raise \n",
        " \n",
        "print(\"no pickle yet, reading data from midis...\") \n",
        "all_files = sorted(glob.glob(search+\"*.mid\") + glob.glob(search+\"*.xml\")) # piano_midis \n",
        "stop_count = len(all_files) if stop_count < 0 or stop_count > len(all_files) else stop_count \n",
        "all_files = all_files[0:stop_count] \n",
        "all_pitches = []\n",
        " \n",
        "print(\"-----\", \"(\", \"debug\" if debug else \"\", len(all_files), \"files\", \")\", \"-----\", end=\"\\n\\n\") \n",
        " \n",
        "for mfile in all_files: \n",
        "    ret = isolate(mfile) \n",
        "    count += 1 \n",
        "    if ret: \n",
        "        print(\"(\", count, \"/\", stop_count, \") \", ret[0], sep=\"\") \n",
        "        piano_part = ret[1] \n",
        "        if count == 1: \n",
        "            piano_part.write('midi', fp=\"music21parse.mid\") \n",
        "        notes, lengths, pitches, offsets = parse_notes(piano_part) \n",
        "        all_pitches.extend(pitches) \n",
        "        vector_list, new_c = map_values(notes, \n",
        "                                  lengths, \n",
        "                                  pitches,\n",
        "                                  offsets,\n",
        "                                  c) \n",
        "        c = new_c \n",
        "        c.mapped_notes.append(vector_list) \n",
        "\n",
        "max_duration = 0\n",
        "for vector_list in c.mapped_notes:\n",
        "    for music_vector in vector_list: \n",
        "        if music_vector[1] > max_duration: \n",
        "            max_duration = music_vector[1]\n",
        "c.max_duration = max_duration\n",
        "\n",
        "if debug: \n",
        "    print(c.mapped_notes) \n",
        "    print(\"sequence_values on\", c.mapped_notes, c.enum_count, c.name_to_num, max_duration, sep=\"\\n\") \n",
        " \n",
        "nw_in, nw_out, new_c, new_n = sequence_values(c, n) \n",
        "c = new_c \n",
        "n = new_n\n",
        "\n",
        "############################################################################### \n",
        "# save sequences into pickle \n",
        "print(\"saving into sequences pickle...\") \n",
        "nwfile = open(nw_pickle, 'wb') \n",
        "print(\"(1/2) network...\") \n",
        "nw = [nw_in, nw_out, c.enum_count, c.max_duration, c.name_to_num] \n",
        "print(\"(2/2) dumping...\") \n",
        "pickle.dump(nw, nwfile) \n",
        "nwfile.close() \n",
        "\n",
        "print(\"saving into normalizers pickle...\")\n",
        "nrmlfile = open(normalize_pickle, 'wb')\n",
        "pickle.dump(n, nrmlfile)\n",
        "print(\"done, starting to train...\") \n",
        "begin_train(nw_in, nw_out, c, n) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}