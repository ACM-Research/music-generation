{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Newest Music Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ACM-Research/music-generation/blob/main/Newest_Music_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co2pZDD4Ql1v"
      },
      "source": [
        "from music21 import converter, interval, instrument, note, chord, common, stream, midi, tempo\n",
        "import glob\n",
        "import concurrent.futures\n",
        "import pickle \n",
        "import numpy as np \n",
        "from keras.utils import np_utils "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtyC8JNRQbZo",
        "outputId": "2e5c426e-166a-4748-807e-8b8145c6a78d"
      },
      "source": [
        "# download \n",
        "%pwd \n",
        "%rm -rf music-generation/ piano_midis/ \n",
        "%rm -rf *.tar.gz \n",
        "# !git clone https://github.com/ACM-Research/music-generation.git # orig. data \n",
        "!wget https://personal.utdallas.edu/~kxs180075/files/pianoonly-xml.tar.gz #anime \n",
        "!wget https://personal.utdallas.edu/~kxs180075/files/pianoonly-midi-full.tar.gz \n",
        "!wget https://personal.utdallas.edu/~kxs180075/files/jazz-xml.tar.gz #13 jazz \n",
        "!wget https://personal.utdallas.edu/~kxs180075/files/bwv806-xml.tar.gz #5 bach \n",
        "!wget https://personal.utdallas.edu/~kxs180075/files/simple-xml.tar.gz #5 simple \n",
        "!tar -xf pianoonly-xml.tar.gz \n",
        "!tar -xf pianoonly-midi-full.tar.gz \n",
        "!tar -xf jazz-xml.tar.gz \n",
        "!tar -xf bwv806-xml.tar.gz \n",
        "!tar -xf simple-xml.tar.gz \n",
        "# %mv -v music-generation/piano_midis ./ "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-23 04:50:47--  https://personal.utdallas.edu/~kxs180075/files/pianoonly-xml.tar.gz\n",
            "Resolving personal.utdallas.edu (personal.utdallas.edu)... 129.110.182.249\n",
            "Connecting to personal.utdallas.edu (personal.utdallas.edu)|129.110.182.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4497283 (4.3M) [application/x-tar]\n",
            "Saving to: ‘pianoonly-xml.tar.gz’\n",
            "\n",
            "pianoonly-xml.tar.g 100%[===================>]   4.29M  2.54MB/s    in 1.7s    \n",
            "\n",
            "2021-04-23 04:50:49 (2.54 MB/s) - ‘pianoonly-xml.tar.gz’ saved [4497283/4497283]\n",
            "\n",
            "--2021-04-23 04:50:49--  https://personal.utdallas.edu/~kxs180075/files/pianoonly-midi-full.tar.gz\n",
            "Resolving personal.utdallas.edu (personal.utdallas.edu)... 129.110.182.249\n",
            "Connecting to personal.utdallas.edu (personal.utdallas.edu)|129.110.182.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4842640 (4.6M) [application/x-tar]\n",
            "Saving to: ‘pianoonly-midi-full.tar.gz’\n",
            "\n",
            "pianoonly-midi-full 100%[===================>]   4.62M  2.93MB/s    in 1.6s    \n",
            "\n",
            "2021-04-23 04:50:51 (2.93 MB/s) - ‘pianoonly-midi-full.tar.gz’ saved [4842640/4842640]\n",
            "\n",
            "--2021-04-23 04:50:51--  https://personal.utdallas.edu/~kxs180075/files/jazz-xml.tar.gz\n",
            "Resolving personal.utdallas.edu (personal.utdallas.edu)... 129.110.182.249\n",
            "Connecting to personal.utdallas.edu (personal.utdallas.edu)|129.110.182.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1198583 (1.1M) [application/x-tar]\n",
            "Saving to: ‘jazz-xml.tar.gz’\n",
            "\n",
            "jazz-xml.tar.gz     100%[===================>]   1.14M  2.76MB/s    in 0.4s    \n",
            "\n",
            "2021-04-23 04:50:52 (2.76 MB/s) - ‘jazz-xml.tar.gz’ saved [1198583/1198583]\n",
            "\n",
            "--2021-04-23 04:50:52--  https://personal.utdallas.edu/~kxs180075/files/bwv806-xml.tar.gz\n",
            "Resolving personal.utdallas.edu (personal.utdallas.edu)... 129.110.182.249\n",
            "Connecting to personal.utdallas.edu (personal.utdallas.edu)|129.110.182.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 221361 (216K) [application/x-tar]\n",
            "Saving to: ‘bwv806-xml.tar.gz’\n",
            "\n",
            "bwv806-xml.tar.gz   100%[===================>] 216.17K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-04-23 04:50:52 (2.08 MB/s) - ‘bwv806-xml.tar.gz’ saved [221361/221361]\n",
            "\n",
            "--2021-04-23 04:50:52--  https://personal.utdallas.edu/~kxs180075/files/simple-xml.tar.gz\n",
            "Resolving personal.utdallas.edu (personal.utdallas.edu)... 129.110.182.249\n",
            "Connecting to personal.utdallas.edu (personal.utdallas.edu)|129.110.182.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22923 (22K) [application/x-tar]\n",
            "Saving to: ‘simple-xml.tar.gz’\n",
            "\n",
            "simple-xml.tar.gz   100%[===================>]  22.39K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2021-04-23 04:50:53 (7.89 MB/s) - ‘simple-xml.tar.gz’ saved [22923/22923]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TU73QhtdhHVV"
      },
      "source": [
        "def isolate(mfile):\n",
        "    # print(\"Reading \", mfile, \" = \", end=\"\") \n",
        "    orig_midi = converter.parse(mfile) \n",
        "    key = orig_midi.analyze(\"key\") \n",
        "    if key.tonic == \"C\": # assume music21 is wrong \n",
        "        return None  \n",
        "    iv = interval.Interval(key.tonic, pitch.Pitch(\"C\")) \n",
        "    midi = orig_midi.transpose(iv) \n",
        "    # print(\"transposed to\", midi.analyze(\"key\").tonic) \n",
        "    midi = midi.flat \n",
        "    parts = instrument.partitionByInstrument(midi)\n",
        "    if parts: \n",
        "        print([instr.partName for instr in parts]) \n",
        "        for instr in parts: \n",
        "            # print(instr.partName, end=\", \") \n",
        "            if instr.partName and \"Piano\" in instr.partName: # xml uses variations like \"Grand Piano\" \n",
        "                return [mfile, instr] \n",
        "\n",
        "    return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRVlmFuj214C"
      },
      "source": [
        "# http://cs229.stanford.edu/proj2018/report/18.pdf \n",
        "# https://www.dropbox.com/sh/ttzb502hheo9fst/AABIlaxy09RRt2b316jcFwIga/LSTM?dl=0&preview=LSTM.py&subfolder_nav_tracking=1 \n",
        "# https://mtosmt.org/issues/mto.13.19.3/mto.13.19.3.tymoczko.pdf \n",
        "def parse_notes(score):\n",
        "    score_elems = score.recurse()\n",
        "\n",
        "    note_list = [] \n",
        "    pitches = [] # [[treble, bass], ...] \n",
        "    elem_lengths = [] # [[treble, bass], ...] \n",
        "    offsets = [] \n",
        "    prev_offset = -1 \n",
        "    for element in score: # score_elems: \n",
        "        # print(element, \"length\", element.duration.quarterLength, \"offset\", element.offset, \"prev\", prev_offset) \n",
        "        if element.duration.quarterLength <= 0: \n",
        "            continue \n",
        "        if isinstance(element, note.Note): \n",
        "            if element.offset != prev_offset: # this is a note in a brand new time offset \n",
        "                note_list.append(str(element.pitch)) \n",
        "                pitches.append([element.pitch]) \n",
        "                elem_lengths.append([round(float(element.duration.quarterLength), 8)]) \n",
        "                offsets.append([float(element.offset)]) \n",
        "            else: # this is still in the old time offset \n",
        "                if len(pitches[-1]) != 2: # and the old time offset can hold more notes \n",
        "                    pitches[-1].append(element.pitch) \n",
        "                    elem_lengths[-1].append(round(float(element.duration.quarterLength), 8)) \n",
        "                    offsets[-1].append(float(element.offset)) \n",
        "            prev_offset = element.offset \n",
        "        elif isinstance(element, chord.Chord): \n",
        "            if element.offset != prev_offset: \n",
        "                temp = '.'.join(str(n.pitch) for n in element)\n",
        "                note_list.append(temp.split('.')) \n",
        "                pitches.append([[k.pitch for k in element]]) # a chord \n",
        "                elem_lengths.append([round(float(element.duration.quarterLength), 8)]) \n",
        "                offsets.append([float(element.offset)]) \n",
        "            else: \n",
        "                if len(pitches[-1]) != 2: \n",
        "                    pitches[-1].append([k.pitch for k in element]) \n",
        "                    elem_lengths[-1].append(round(float(element.duration.quarterLength), 8)) \n",
        "                    offsets[-1].append(float(element.offset)) \n",
        "            prev_offset = element.offset \n",
        "        elif isinstance(element, note.Rest):\n",
        "            if element.offset != prev_offset: \n",
        "                note_list.append(None) \n",
        "                pitches.append([None]) \n",
        "                elem_lengths.append([round(float(element.duration.quarterLength), 8)]) \n",
        "                offsets.append([float(element.offset)]) \n",
        "            else: \n",
        "                if len(pitches[-1]) != 2: \n",
        "                    pitches[-1].append(None) \n",
        "                    elem_lengths[-1].append(round(float(element.duration.quarterLength), 8)) \n",
        "                    offsets[-1].append(float(element.offset)) \n",
        "            prev_offset = element.offset \n",
        "        else:\n",
        "            # print(\"None of the above\", element)\n",
        "            # prev_offset = element.offset \n",
        "            pass \n",
        "    # print(\"parse_notes pitches\", pitches) \n",
        "    def fixitup(arr, addNone=True): \n",
        "        for frame in arr: \n",
        "            if len(frame) < 2: \n",
        "                if addNone: \n",
        "                    frame.append(None) \n",
        "                else: \n",
        "                    frame.append(frame[0]) # (frame[0]) \n",
        "    fixitup(pitches, addNone=True) \n",
        "    fixitup(elem_lengths, addNone=False) \n",
        "    fixitup(offsets) \n",
        "     \n",
        "    return (note_list, elem_lengths, pitches, offsets) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgdG1NK4ZN8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a478a2-69ae-47a9-8132-f2a8285c6905"
      },
      "source": [
        "from music21 import pitch \n",
        "c = pitch.Pitch(63) \n",
        "print(c, pitch.Pitch(63).ps == pitch.Pitch(\"Eb4\").ps == pitch.Pitch('D#4').ps) \n",
        " \n",
        "def numerical(name): \n",
        "    try: \n",
        "        return pitch.Pitch(name).ps \n",
        "    except Exception: \n",
        "        print(\"Bad name\", name)\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E-4 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ0-lKJt27ID"
      },
      "source": [
        "def pstr(mpitch): \n",
        "    #print(mpitch) \n",
        "    def octv(k): \n",
        "        v = k.octave \n",
        "        # v = 4 \n",
        "        r = pitch.Pitch(k.name+str(v)) \n",
        "        return r \n",
        "    if not mpitch or (isinstance(mpitch, str) and \"r\" in mpitch):\n",
        "        return \"r\" #frozenset([\"r\"]) # \n",
        "    if isinstance(mpitch, str) and \"b\" in mpitch: \n",
        "        print(\"b is not allowed!\") \n",
        "        raise \n",
        "        return \"r\" \n",
        "    if isinstance(mpitch, list) or isinstance(mpitch, set): \n",
        "        mpitch = [octv(k) for k in mpitch] \n",
        "        return \"-\".join([str(k.ps) for k in mpitch]) # frozenset([str(k.ps) for k in mpitch]) # inverted chords are now considered the same # \"-\".join # str(k.ps) \n",
        "    else: \n",
        "        mpitch = octv(mpitch) \n",
        "        return str(mpitch.ps) # frozenset([str(mpitch.ps)]) # str(mpitch.ps) \n",
        "\n",
        "def map_values(notes, lengths, pitches, offsets, counter): # enum_count, all_names, name_to_num): \n",
        "    # lengths, pitches = [k[0] for k in lengths], [k[0] for k in pitches] \n",
        "    enum_count, all_names, name_to_num = counter.enum_count, counter.all_names, counter.name_to_num \n",
        "    # print(enum_count) \n",
        "    # all_names: this song. pstr: converts a pitch into a string. \n",
        "    all_names = [pstr(k[0]) for k in pitches] + [pstr(k[1]) for k in pitches] \n",
        "    for k in all_names:\n",
        "      if k not in name_to_num:\n",
        "          name_to_num[k] = enum_count\n",
        "          enum_count += 1\n",
        "    # index = 0 \n",
        "    vector_list = []\n",
        "    for index in range(min(len(pitches), len(lengths))): # for item in all_names: # 64-63-23 \n",
        "        music_vector = []\n",
        "        length = max(lengths[index][0], lengths[index][1]) # length of this frame \n",
        "        # offset = offsets[index]\n",
        "        # print(item, length) \n",
        "        if length <= 8: \n",
        "            treble, bass = pstr(pitches[index][0]), pstr(pitches[index][1]) \n",
        "            treble_length, bass_length = lengths[index][0], lengths[index][1] \n",
        "            music_vector = [name_to_num[treble], treble_length, name_to_num[bass], bass_length] \n",
        "            # if \"r\" not in item: \n",
        "            #     music_vector = [name_to_num[item], length] \n",
        "            # else: \n",
        "            #     music_vector = [0, length] \n",
        "            vector_list.append(music_vector)\n",
        "        else:\n",
        "            pass # print(\"Threw away note of length\", length) \n",
        "        # index += 1 \n",
        "    # print(vector_list)\n",
        "    counter.enum_count = enum_count \n",
        "    counter.all_names = all_names \n",
        "    counter.name_to_num = name_to_num \n",
        "    return (vector_list, counter) \n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7pDEUP-TwC0"
      },
      "source": [
        "%rm -rvf stream* "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCy8Xqj16uqT"
      },
      "source": [
        "import sys \n",
        "import copy \n",
        "import math \n",
        "from numpy import argmax \n",
        "from keras.utils import normalize, to_categorical \n",
        "def qround(value): \n",
        "    return math.ceil(value*4)/4 \n",
        "def sequence_values(counter, normalizers): # mapped_notes, enum_count, name_to_num, \n",
        "    mapped_notes, enum_count, name_to_num = counter.mapped_notes, counter.enum_count, counter.name_to_num \n",
        "    max_duration = counter.max_duration\n",
        "    max_offset = counter.max_offset\n",
        "    seq_size = normalizers.seq_size \n",
        "    # mapped_notes = [ song, song, song ] \n",
        "    # song = [ [pitch, duration], [pitch, duration], ... ] \n",
        "    # print(mapped_notes[0][0:100]) \n",
        "    nw_in, nw_out = [], [] \n",
        "    all_pkgs = set() \n",
        "    # input [100 of [pitch, duration]], output next pitch name\n",
        "    for vector_list in mapped_notes: \n",
        "        # print(\"origin\", vector_list[:10], \"...\") \n",
        "        for idx in range(0, len(vector_list)): \n",
        "            music_vector = copy.deepcopy(vector_list[idx]) \n",
        "            # print(music_vector, \"with enum_count\", enum_count, \"and max_duration\", max_duration)\n",
        "            # result = (75, 0.6) where 75 => pitch/chord mapping and 0.6 => quarter length \n",
        "            result = (music_vector[0], qround(music_vector[1]), \n",
        "                      music_vector[2], qround(music_vector[3])) \n",
        "            all_pkgs.add(result) \n",
        "            # music_vector[2] = music_vector[2]/max_offset\n",
        "            vector_list[idx] = result \n",
        "         \n",
        "        # print(\"nmlized\", vector_list[:10], \"...\") \n",
        "    pkg_to_int = dict([(pkg, number) for number, pkg in enumerate(list(all_pkgs))]) \n",
        "    mean, std = np.mean(list(pkg_to_int.values())), np.std(list(pkg_to_int.values())) \n",
        "    print(\"packaged notes, there are\", len(pkg_to_int), \"packages. \\n\\tpkgs=\", list(all_pkgs)[0:5], \"...\") \n",
        "    for vector_list in mapped_notes: \n",
        "        for k in range(0, len(vector_list) - seq_size - 1): \n",
        "            window = vector_list[k:k+seq_size] # [[pitch, duration], ...] \n",
        "            expected = vector_list[k+seq_size] # [pitch, duration] \n",
        "            # print(window, \"\\t and expected is\", expected, sep=\"\\n\") \n",
        "            nw_in.append([pkg_to_int[k] for k in window]) \n",
        "            nw_out.append(pkg_to_int[expected]) \n",
        "    # nw_in, nw_out = None, None \n",
        "    # mstream = unmap_values(nw_in[0], counter) \n",
        "    # print(\"Output stream midi file\") \n",
        "    # mstream.write('midi', fp=\"stream_\"+str(datetime.now())+\"_demo.mid\") \n",
        "    # sys.exit(0) \n",
        "    print(\"Our code is done,\", len(nw_in), len(nw_out)) \n",
        "    num_pkgs, num_windows, seq_size = len(pkg_to_int), len(nw_in), len(nw_in[0]) \n",
        "    normalizers.mpc, normalizers.spc, normalizers.mln, normalizers.sln = 0, 0, 0, 0 \n",
        "    normalizers.pkg_to_int = pkg_to_int \n",
        "    normalizers.mean, normalizers.std = mean, std \n",
        "    normalizers.num_pkgs = num_pkgs \n",
        "    # print(nw_in[0:100], nw_out[:100], sep=\"\\n\") \n",
        "    print(num_windows, \"windows, each with\", seq_size, \"frames, (each with\", 4, \"features that map to 1 number), \", \n",
        "        \"total=window*frame*1=\", num_windows*seq_size*1) \n",
        "    nw_in = np.array(nw_in).astype(np.float32) \n",
        "    nw_out = np.array(nw_out).astype(np.float32) \n",
        "     \n",
        "    nw_in = np.reshape(nw_in, (num_windows, seq_size, 1)) \n",
        "    nw_out = to_categorical(nw_out) # reshapes to (num_pkgs, num_pkgs) \n",
        "    # nw_out = np.reshape(nw_out, (num_windows, 4)) \n",
        "\n",
        "    print(\"Input and output shapes:\", nw_in.shape, nw_out.shape) \n",
        "    return (nw_in, nw_out, counter, normalizers) \n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhAx4TSIvZzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf19535-4fa2-47db-cf48-ff067b1999b5"
      },
      "source": [
        "!pip install keras-self-attention \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Activation, Dense, Bidirectional, LSTM, Dropout, Flatten, TimeDistributed, Reshape \n",
        "from keras.callbacks import ModelCheckpoint \n",
        "from keras.optimizers import SGD \n",
        "from keras.optimizers import Adam \n",
        "from keras_self_attention import SeqSelfAttention\n",
        "# https://stackoverflow.com/a/37213763 \n",
        "def basic_network(counter, normalizers): # * \n",
        "    model = Sequential() \n",
        "    # model.add(Bidirectional(LSTM(256, input_shape=(seq_size, 4), return_sequences=True))) # 256 \n",
        "    model.add(LSTM(512, input_shape=(normalizers.seq_size, 1), return_sequences=True)) \n",
        "    # model.add(TimeDistributed(Dense(4))) \n",
        "    model.add(SeqSelfAttention(attention_activation='linear')) # linear \n",
        "    model.add(LSTM(512, input_shape=(normalizers.seq_size, 1), return_sequences=False)) \n",
        "    model.add(Flatten()) \n",
        "    model.add(Dense(normalizers.num_pkgs)) \n",
        "    model.add(Activation('softmax')) # * linear, softmax, sigmoid ? \n",
        "    opt = Adam(learning_rate=1e-4) # SGD(lr=1e-3) # Adam(learning_rate=0.005) # opt = SGD(lr=0.005) # 1e-3) # * \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) # loss mae, mse, categorical_crossentropy, opt rmsprop \n",
        "    # print(\"Building model......\")\n",
        "    # model = Sequential() # initialize a sequential model \n",
        "    # model.add(LSTM(512,return_sequences=False, input_shape=(100, 3))) # 2nd layer of LSTM \n",
        "    # model.add(Dropout(0.75)) # 2nd layer of Dropout\n",
        "    # model.add(Dense(3)) # a dense layer of 3 tensors \n",
        "    # model.add(Activation('linear'))\n",
        "    # model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    return model \n",
        "def load_model(filename, counter, normalizers): \n",
        "    model = basic_network(counter, normalizers) \n",
        "    model.load_weights(filename) \n",
        "    return model \n",
        "def train(model, nw_in, nw_out, num_epochs=100): \n",
        "    fp = \"weights.best.hdf5\" \n",
        "    checkpoint = ModelCheckpoint(fp, monitor='loss', verbose=1, save_best_only=True) \n",
        "    model.fit(nw_in, nw_out, epochs=num_epochs, batch_size=256, callbacks=[checkpoint]) \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-self-attention\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/34/e21dc6adcdab2be03781bde78c6c5d2b2136d35a1dd3e692d7e160ba062a/keras-self-attention-0.49.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (1.19.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-self-attention) (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras-self-attention) (1.15.0)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.49.0-cp37-none-any.whl size=19468 sha256=f9305b951e1ac797f11f8ede8cdd1dd50c5044c48a6c841c288d2b68e23af859\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/9d/c5/26693a5092d9313daeae94db04818fc0a2b7a48ea381989f34\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.49.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRZo_XycDaXd"
      },
      "source": [
        "def unmap_values(complete, counter, normalizers):\n",
        "    # input: list of music vectors, counter object\n",
        "    # output: music21 stream object\n",
        "    # music_stream = stream.Stream()\n",
        "    print(\"spc: \", normalizers.spc)\n",
        "    print(\"mpc: \", normalizers.mpc)\n",
        "    print(\"sln: \", normalizers.sln)\n",
        "    print(\"mln: \", normalizers.mln)\n",
        "    top, bottom = stream.Part(), stream.Part() \n",
        "    int_to_pkg = {num:name for name, num in normalizers.pkg_to_int.items()} \n",
        "    print(\"int_to_pkg len \", len(int_to_pkg), \": \", int_to_pkg) \n",
        "    num_to_name = {num:name for name, num in counter.name_to_num.items()}\n",
        "    off, count = 0, 0 \n",
        "    top.insert(0, instrument.Piano()) \n",
        "    bottom.insert(0, instrument.Piano()) \n",
        "    # print(num_to_name)\n",
        "    def add_to_stream(category, is_treble, i, j, off=0): \n",
        "        music_vector = int_to_pkg[category] # actually a tuple \n",
        "        pitch, length = music_vector[i], music_vector[j] \n",
        "        # pitch, length = music_vector[i], music_vector[j]\n",
        "\n",
        "        # # doing this ruins normalisation\n",
        "        # pitch = abs(pitch)\n",
        "        # length = abs(length) \n",
        "\n",
        "        # pitch = pitch*normalizers.spc + normalizers.mpc\n",
        "        # length = float(length*normalizers.sln + normalizers.mln)\n",
        "        \n",
        "        pitch = round(pitch)\n",
        "        if length < 0 or pitch < 0:\n",
        "            print(\"ERR \", is_treble, \")\", [length, pitch])\n",
        "            return\n",
        "        # offset = music_vector[2] * counter.max_offset\n",
        "        # print(music_vector) \n",
        "        if length > 8: \n",
        "            length = 0.5 \n",
        "        if pitch not in num_to_name.keys(): \n",
        "            print(\"ERR\", is_treble, \")\", category, \"=>\", music_vector, \"=>\", [pitch, length], \"=>\", \"?\") \n",
        "            return \n",
        "        elem_name = num_to_name[pitch] # num_to_name[pitch], \"-\".join(list(num_to_name[pitch])) \n",
        "        if elem_name == 'b': \n",
        "            return # refuse to add anything to stream \n",
        "        if elem_name == 'r':\n",
        "            elem = note.Rest() \n",
        "        elif '-' not in elem_name:\n",
        "            elem = note.Note(int(float(elem_name)))\n",
        "        else:\n",
        "            pitch_arr = elem_name.split('-')\n",
        "            pitch_arr = [int(float(x)) for x in pitch_arr]\n",
        "            elem = chord.Chord(pitch_arr)\n",
        "            \n",
        "        elem.storedInstrument = instrument.Piano()\n",
        "        elem.duration.quarterLength = length\n",
        "        # elem.offset = off \n",
        "        if is_treble: \n",
        "            top.insert(off, elem) # top.append(elem) # top.insert(off, elem) \n",
        "        else: \n",
        "            bottom.insert(off, elem) # bottom.append(elem) # bottom.insert(off, elem) \n",
        "        print(is_treble, \")\", category, \"=>\", music_vector, \"=>\", [pitch, length], \"=>\", \n",
        "              elem, \", length:\", elem.duration.quarterLength, \", off:\", off, \", offset:\", elem.offset) \n",
        "        return elem \n",
        "\n",
        "    for category in complete: \n",
        "        # while len(music_vector) < 4: \n",
        "        #     music_vector.append(0.5) \n",
        "        tre = add_to_stream(category, True, 0, 1, off) \n",
        "        bae = add_to_stream(category, False, 2, 3, off) \n",
        "        off += 0.5 \n",
        "        #off += max(0.5, \n",
        "                   #max(tre.duration.quarterLength, bae.duration.quarterLength)) \n",
        "        # music_stream.append(elem) \n",
        "        count += 1 \n",
        "\n",
        "    music_stream = stream.Stream([top, bottom]) \n",
        "    return music_stream\n",
        "\n",
        "from datetime import datetime \n",
        "def stream_file(stream, title=\"\"): # todo use array of streams \n",
        "    %mkdir -p stream_out \n",
        "    %cd stream_out \n",
        "    stream.write('midi', fp=\"stream_\"+str(datetime.now())+\"_demo\"+title+\".mid\") \n",
        "    %cd .. \n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWux_8d-O-Sq"
      },
      "source": [
        "import copy \n",
        "# import tensorflow as tf\n",
        "def use_model(model, nw_in, counter): \n",
        "    # nw_in is [window, window, ...] \n",
        "    start = int(len(nw_in)/4) # 0 # int(len(nw_in)/2) # 0 \n",
        "    pattern_in = list(nw_in[start]) # python list of ndarrays dtype=float32. do not convert ndarray to python list. len of pattern_in is sequence size. \n",
        "    seq_size = len(pattern_in) \n",
        "    complete = list(nw_in[start]) # .tolist() \n",
        "    print(\"starting sequence window\", complete[0:10], \"...\") # pattern_in) \n",
        "    for idx in range(200): \n",
        "        print(\"generating note\", idx, \"...\") \n",
        "        # print(\"\\tPY INPUT\", pattern_in[0:3], \"...\") \n",
        "        ptn = np.asarray(pattern_in) \n",
        "        prediction_input = np.reshape(ptn, (1, seq_size, -1)) # np.reshape(ptn, (1, len(ptn), 2)) # np.array(pattern_in)\n",
        "        # print(\"\\tINPUT\", prediction_input, sep=\"\\n\") \n",
        "        # print(type(prediction_input), type(prediction_input[0]), type(prediction_input[0][0]), type(prediction_input[0][0][0]))\n",
        "        \n",
        "        # print(\"\\tINPUT SHAPE\", prediction_input.shape) \n",
        "        prediction = model.predict(prediction_input, verbose=0) # confidences where each index is a category \n",
        "        num_cat = len(prediction[0]) \n",
        "        # print(\"\\tPREDICTIONS\", prediction) \n",
        "        predicted_next = np.argmax(prediction) \n",
        "        if idx % 4 == 0: \n",
        "            predicted_next = np.random.choice(num_cat, 1, p=prediction[0])[0] # np.argmax(prediction) # highest conf. index # .tolist() \n",
        "        # print(\"\\tOUTPUT\", predicted_next) \n",
        "        complete.append(np.asarray(predicted_next, dtype='float32').reshape(1)) # numpy array reshape into list. so 419 => nparray(419.0) => nparray([419.0]) \n",
        "        # print(\"\\tSO FAR\", complete[:2], \"...\", complete[-2:]) \n",
        "        # pattern_in += predicted_next # np.concatenate(pattern_in, predicted_next) \n",
        "        pattern_in = complete[idx:idx+seq_size] #len(complete) - 1] # pattern_in[1:len(pattern_in)] \n",
        "    return [int(k) for k in complete] # int() will attempt to coerce numpy predictions. python list of ints. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF18-wTffQS8"
      },
      "source": [
        "def begin_train(nw_in, nw_out, counter, normalizers): \n",
        "    model = basic_network(counter, normalizers) \n",
        "    model.summary() \n",
        "    train(model, nw_in, nw_out, num_epochs=500) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs5762tD3Mpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e022114-a021-4127-ec4f-5950f055f124"
      },
      "source": [
        "import os.path \n",
        "import math \n",
        "import sys \n",
        "from datetime import datetime \n",
        "# read data -> \n",
        "# map input (note:num) -> \n",
        "# sequence input (num to 0..1) then (window to next) -> \n",
        "# package network input it into 1 pickle -> \n",
        "# train -> \n",
        "# save best into hdf5 -> \n",
        "# use hdf5 to generate new notes -> \n",
        "# unmap (0..1 to num) then (num:note) -> \n",
        "# add to stream -> \n",
        "# output midi file \n",
        "count = 0 \n",
        "cpus = 16 \n",
        "debug, stop_count = False, 20 \n",
        "nw_pickle, search = \"nw.pkl\", './pianoonly-xml/' # \"./pianoonly-xml/\" # \"./simple-xml/\" # \"./chorales/xml/\" # \"./pianoonly-xml/\"\n",
        "normalize_pickle = \"normalize.pkl\"\n",
        "!rm -v music21parse.mid unmap_demo.mid \n",
        "\n",
        "class Counters:\n",
        "    def __init__(self):\n",
        "        self.enum_count = 0 \n",
        "        self.unique_frames = 0 \n",
        "        self.all_names = [] \n",
        "        self.name_to_num = {} \n",
        "        self.mapped_notes = [] \n",
        "        self.max_duration = 0\n",
        "        self.max_offset = 0\n",
        "\n",
        "class Normalization:\n",
        "    def __init__(self): \n",
        "        self.pkg_to_int = dict() \n",
        "        self.num_pkgs = 0 \n",
        "        self.mean = 0 \n",
        "        self.std = 0 \n",
        "        self.seq_size = 64 \n",
        "        self.mpc = 0 \n",
        "        self.spc = 0 \n",
        "        self.mln = 0 \n",
        "        self.sln = 0 \n",
        "     \n",
        "c = Counters()\n",
        "n = Normalization()\n",
        "if os.path.isfile(nw_pickle): \n",
        "    print(\"this is just to let you know that the network pickle file is being used, press any key to confirm\") \n",
        "    consume = input() \n",
        "    print(\"reading from network pickle...\") \n",
        "    nwfile = open(nw_pickle, \"rb\") \n",
        "    print(\"(1/2) loading...\") \n",
        "    nw = pickle.load(nwfile) \n",
        "    print(\"(2/2) parsing...\") \n",
        "    nw_in, nw_out, c.enum_count, c.max_duration, c.name_to_num = nw[0], nw[1], nw[2], nw[3], nw[4] \n",
        "    nwfile.close() \n",
        "    print(\"nw_out:\", list(nw_out[:3]), \"...\") \n",
        "    print(\"nw_out has\", len(nw_out), \"notes, about\", math.ceil(len(nw_out)/450), \"songs\") \n",
        "    print(\"enum_count\", nw[2], \"max_duration\", nw[3]) \n",
        "    print(\"name_to_num has keys\", list(nw[4].keys())[:5], \"...\") \n",
        "    print(\"done, starting to train...\")\n",
        "\n",
        "    print(\"reading from normalizers pickle...\")\n",
        "    nrmlfile = open(normalize_pickle, \"rb\")\n",
        "    print(\"(1/2) loading...\") \n",
        "    n = pickle.load(nrmlfile)\n",
        "    print(\"(2/2) parsing...\") \n",
        "    print(\"there are\", len(n.pkg_to_int), \"categories\") \n",
        "    # begin_train(nw_in, nw_out) \n",
        "    # exit(0)  \n",
        "    if os.path.isfile(\"weights.best.hdf5\"): \n",
        "        print(\"generating notes...\")\n",
        "        ###########\n",
        "        # use the model for prediction \n",
        "        # \n",
        "        model = load_model(\"weights.best.hdf5\", c, n) \n",
        "        result = use_model(model, nw_in, c) \n",
        "        print(\"RESULT\", result) \n",
        "        result_stream = unmap_values(result, c, n) \n",
        "        print(\"Output result midi file\")\n",
        "        result_stream.write('midi', fp=\"generated_\"+str(datetime.now())+\"_demo.mid\")\n",
        "        raise \n",
        "    else: \n",
        "        begin_train(nw_in, nw_out, c, n) \n",
        "        raise \n",
        " \n",
        "# otherwise, do map and sequencing ############################################ \n",
        "print(\"no pickle\") \n",
        "all_files = sorted(glob.glob(search+\"*.mid\") + glob.glob(search+\"*.xml\")) # piano_midis \n",
        "stop_count = len(all_files) if stop_count < 0 or stop_count > len(all_files) else stop_count \n",
        "all_files = all_files[0:stop_count] \n",
        "all_pitches = []\n",
        " \n",
        "print(\"-----\", \"(\", \"debug\" if debug else \"\", len(all_files), \"files\", \")\", \"-----\", end=\"\\n\\n\") \n",
        " \n",
        "# one worker per core\n",
        "# with concurrent.futures.ThreadPoolExecutor(max_workers=cpus) as executor:\n",
        "    # for ret in executor.map(isolate, all_files): \n",
        "for mfile in all_files: \n",
        "    ret = isolate(mfile) \n",
        "    count += 1 \n",
        "    if ret: \n",
        "        print(\"(\", count, \"/\", stop_count, \") \", ret[0], sep=\"\") \n",
        "        piano_part = ret[1] \n",
        "        if count == 1: \n",
        "            piano_part.write('midi', fp=\"music21parse.mid\") \n",
        "        notes, lengths, pitches, offsets = parse_notes(piano_part) \n",
        "        # fixme shouldn't add pitches like this because they'll overlap with the window regardless of the song..., and it's super bad \n",
        "        # try: \n",
        "        all_pitches.extend(pitches) \n",
        "        # print(len(notes), len(lengths), len(pitches))\n",
        "        vector_list, new_c = map_values(notes, \n",
        "                                  lengths, \n",
        "                                  pitches,\n",
        "                                  offsets,\n",
        "                                  c) \n",
        "        c = new_c \n",
        "        c.mapped_notes.append(vector_list) \n",
        "\n",
        "max_duration = 0\n",
        "for vector_list in c.mapped_notes:\n",
        "    for music_vector in vector_list: \n",
        "        # print(music_vector, max_duration) \n",
        "        if music_vector[1] > max_duration: \n",
        "            # print(music_vector) \n",
        "            max_duration = music_vector[1]\n",
        "c.max_duration = max_duration\n",
        "\n",
        "# max_offset = 0\n",
        "# for vector_list in c.mapped_notes:\n",
        "#     for music_vector in vector_list: \n",
        "#         # print(music_vector, max_duration) \n",
        "#         if music_vector[2] > max_offset: \n",
        "#             # print(music_vector) \n",
        "#             max_offset = music_vector[2]\n",
        "# c.max_offset = max_offset\n",
        "if debug: \n",
        "    print(c.mapped_notes) \n",
        "    print(\"sequence_values on\", c.mapped_notes, c.enum_count, c.name_to_num, max_duration, sep=\"\\n\") \n",
        "\n",
        "# Testing the unmap notes function\n",
        "# Problem is with notes being overlaid. {offset} rather than length? or offset and length? not sure\n",
        "# test_output = c.mapped_notes[0]\n",
        "# print(test_output)\n",
        "# for music_vector in test_output:\n",
        "#     music_vector[0] /= c.enum_count\n",
        "#     music_vector[1] /= c.max_duration\n",
        "#     # music_vector[2] /= c.max_offset \n",
        "\n",
        "# music_stream = unmap_values(test_output, c)\n",
        "\n",
        "# # print(music_stream.show('text'))\n",
        "\n",
        "# print(\"Outputting test midi file...\")\n",
        "# music_stream.write('midi', fp=\"unmap_demo.mid\")\n",
        "\n",
        "\n",
        " \n",
        "nw_in, nw_out, new_c, new_n = sequence_values(c, n) \n",
        "c = new_c \n",
        "n = new_n\n",
        "#print(nw_in[40:50]) \n",
        "# vocab = set([pstr(k) for k in all_pitches]) \n",
        "# print(\"done, saw\", len(all_pitches), \"pitches,\", len([k for k in vocab if \"-\" in k]), \"unique chords and\", \n",
        "#        len([k for k in vocab if \"-\" not in k]), \"unique pitches (excluding chords)\") \n",
        "exit(1) \n",
        "############################################################################### \n",
        "# save into pickle \n",
        "# !rm -rvf \n",
        "print(\"saving into sequences pickle...\") \n",
        "nwfile = open(nw_pickle, 'wb') \n",
        "print(\"(1/2) network...\") \n",
        "nw = [nw_in, nw_out, c.enum_count, c.max_duration, c.name_to_num] \n",
        "print(\"(2/2) dumping...\") \n",
        "pickle.dump(nw, nwfile) \n",
        "nwfile.close() \n",
        "\n",
        "print(\"saving into normalizers pickle...\")\n",
        "nrmlfile = open(normalize_pickle, 'wb')\n",
        "pickle.dump(n, nrmlfile)\n",
        "print(\"done, starting to train...\") \n",
        "begin_train(nw_in, nw_out, c, n) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'music21parse.mid': No such file or directory\n",
            "rm: cannot remove 'unmap_demo.mid': No such file or directory\n",
            "no pickle\n",
            "----- (  20 files ) -----\n",
            "\n",
            "['Grand Piano']\n",
            "(1/20) ./pianoonly-xml/ACruelAngelsThesis.mid.xml\n",
            "['Grand Piano, CFX Concert Grand 1']\n",
            "(2/20) ./pianoonly-xml/ADAMAS(Theishter).mid.xml\n",
            "['Grand Piano, Piano']\n",
            "(3/20) ./pianoonly-xml/ADAMASOG.mid.xml\n",
            "['Grand Piano, SmartMusic SoftSynth']\n",
            "(4/20) ./pianoonly-xml/AOHARUOP.mid.xml\n",
            "['Bright Piano, Solo']\n",
            "(5/20) ./pianoonly-xml/AOTOP2.mid.xml\n",
            "['Grand Piano, Piano']\n",
            "(6/20) ./pianoonly-xml/APageofMySto…PrincipalED).mid.xml\n",
            "['Grand Piano, Piano']\n",
            "(7/20) ./pianoonly-xml/AQUA.mid.xml\n",
            "['Grand Piano']\n",
            "(8/20) ./pianoonly-xml/ARIA_The_ORIGINA…achi-_Spirale.mid.xml\n",
            "['Grand Piano, Piano']\n",
            "(9/20) ./pianoonly-xml/ATenderFeeling.mid.xml\n",
            "['Grand Piano, New Instrument']\n",
            "(10/20) ./pianoonly-xml/A_Cruel_Angels_Thesis.mid.xml\n",
            "['Grand Piano']\n",
            "(11/20) ./pianoonly-xml/A_Tender_Feeling…sbeths_Theme].mid.xml\n",
            "['Grand Piano']\n",
            "(12/20) ./pianoonly-xml/AcediaMIDI.mid.xml\n",
            "['Grand Piano']\n",
            "(13/20) ./pianoonly-xml/Achildwhowant…obethewind.mid.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeVk_X0B0Bh9"
      },
      "source": [
        "# !rm -rvf generated* stream* "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}